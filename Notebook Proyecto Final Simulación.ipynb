{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports iniciales\n",
    "Se realizan los siguientes imports:\n",
    " - arff para la apertura del archivo de datos\n",
    " - pandas para el manejo de datos en tablas\n",
    " - numpy para el manejo de operaciones matemáticas y manipulación de matrices, listas y arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install qgrid\n",
    "!pip install scipy\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qgrid\n",
    "\n",
    "\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "#ETAPA 1: Extracción de los datos desde archivo .arff obtenido de UCI\n",
    "ds = arff.loadarff('PhishingData.arff')\n",
    "df = pd.DataFrame(ds[0])\n",
    "df.head()\n",
    "dataset = df.to_numpy()\n",
    "X_parcial = dataset[: , 0:9]\n",
    "Y_parcial = dataset[: , 9]\n",
    "X = np.zeros(len(X_parcial))\n",
    "Y = np.zeros(len(Y_parcial))\n",
    "j = 0\n",
    "for i in Y_parcial:\n",
    "    s = i.decode('UTF-8')\n",
    "    Y[j] = int(s)\n",
    "    j = j + 1\n",
    "X_lista = list()\n",
    "for i in X_parcial:\n",
    "    lista = list()\n",
    "    for k in i:\n",
    "        s = k.decode('UTF-8')\n",
    "        lista.append(int(s))\n",
    "    X_lista.append(lista)\n",
    "X = np.asarray(X_lista)\n",
    "\n",
    "# ¿CUÁNTAS MUESTRAS HAY? ¿CUÁNTAS CARACTERÍSTICAS TIENE EL PROBLEMA?\n",
    "muestras = len(X)\n",
    "print(\"Hay \" + str(muestras) + \" muestras en el conjunto de datos.\")\n",
    "caracteristicas = len(X[0])\n",
    "print(\"Hay \" + str(caracteristicas) + \" características en el conjunto de datos.\")\n",
    "\n",
    "\n",
    " #####################################################################################\n",
    "\n",
    "\n",
    "#Función para calcular error de clasificación\n",
    "def error(Y_lest, Y):\n",
    "    error = 0\n",
    "    for ye, y in zip(Y_lest, Y):\n",
    "        if ye != y:\n",
    "            error += 1\n",
    "    error = error/np.size(Y)\n",
    "    return error\n",
    "\n",
    "\n",
    " #####################################################################################\n",
    "\n",
    "\n",
    "#ETAPA 2: Ejecución de validación cruzada, clasificación k-vecinos\n",
    "def k_vecinos(n_vec):\n",
    "    folds = 4\n",
    "    skf = StratifiedKFold(n_splits = folds)\n",
    "    vec_error_clasif = np.zeros(folds)\n",
    "    j = 0\n",
    "    for train_index, test_index in skf.split(X , Y):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        #En un sólo pipeline se estandarizan y se procesan los datos con el clasificador_knn\n",
    "        clasificador_knn = Pipeline([('scaler', StandardScaler()),('knn', KNeighborsClassifier(n_neighbors = n_vec))])\n",
    "        clasificador_knn.fit(X_train , Y_train)\n",
    "        Yestim = clasificador_knn.predict(X_test)\n",
    "        vec_error_clasif[j] = error(Yestim, Y_test)\n",
    "        j = j + 1\n",
    "    return np.mean(vec_error_clasif) , np.std(vec_error_clasif)\n",
    "\n",
    "\n",
    " #####################################################################################\n",
    "\n",
    "\n",
    "# Obtención tabla para determinar número óptimo de vecinos\n",
    "df_types = pd.DataFrame({'Numero de vecinos' : pd.Series(['1', '2', '3', '4', '5', '6', '7', '100'])})\n",
    "df_types[\"Error_Prueba\"] = pd.Series()\n",
    "df_types[\"Desviación estándar del error\"] = \"\"\n",
    "\n",
    "numero_vecinos = [1, 2, 3, 4, 5, 6, 7, 100]\n",
    "for i in range(len(numero_vecinos)):\n",
    "    errorprueba, desvesterror = k_vecinos(numero_vecinos[i])\n",
    "    print('\\nEjecución ' + str(i + 1) + ' lista.' + '\\nFaltan ' + str(len(numero_vecinos) - i - 1) + ' ejecuciones.\\n')\n",
    "    df_types.loc[i, \"Error_Prueba\"] = errorprueba # cambiar por el valor correcto\n",
    "    df_types.loc[i, \"Desviación estándar del error\"] = desvesterror  # cambiar por el valor correcto\n",
    "\n",
    "#df_types.loc[1, \"Error_Prueba\"] = \"0.3630\" # cambiar por el valor correcto\n",
    "#df_types.loc[1, \"Desviación estándar del error\"] = \"0.0061\"  # cambiar por el valor correcto\n",
    "#df_types.sort_index(inplace=True)\n",
    "\n",
    "df_types.set_index(['Numero de vecinos'], inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget.get_changed_df()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
